\begin{frame}{Outline}
	\definecolor{prediction}{HTML}{b30000}
	\newcommand{\arrowlenshort}{2.2cm}
	\newcommand{\arrowlen}{2.9cm}
	\hspace*{-1.7cm}
	\begin{tikzpicture}[
			>=stealth,
			block/.style={draw, rectangle, minimum height=1.2cm, minimum width=2.2cm, text width=2.3cm,},
			node distance=\arrowlen
		]

		\node[block,align=center] (u) {System\\Discretization};
		\node[block, right=of u, align=center] (sys) {Discretize\\Perf. Index $\mathcal{J}$};\node[block, right=of sys,xshift=-0.7cm, align=center] (dp) {Dynamic\\Programming};
		\node[block, align=center, below=0.7cm of u,color=prediction] (sample) {Sampling\\ Method};

		\draw[->] ($(u.west)+(-\arrowlenshort,0.2cm)$) -- ($(u.west)+(0,0.2cm)$)
		node[midway, above] {$\dot{x}= Ax + Bu$};


		% \draw[->] ($(u.west)+(-\arrowlenshort,-0.2cm)$) -- ($(u.west)+(0,-0.2cm)$)
		%     node[midway, below] {$\{ t_0, \, \ldots, t_N \}$};

		\draw[->, color=prediction, thick]
		($(sample.west)+(0,0)$)
		-- ($(sample.west)+(-\arrowlenshort,0)$)  % horizontal line to original start of arrow
		% start at middle of left side of Sampling box
		-- ($(u.west)+(-\arrowlenshort,-0.2cm)$)  % horizontal line to original start of arrow
		-- ($(u.west)+(0,-0.2cm)$)                % original arrow path
		node[midway, below, color=prediction, thick] {$\{ t_0, \ldots, t_N \}$};



		\draw[->]
		($(u.east)+(0,0.2cm)$) -- ++(\arrowlen,0)
		node[midway, above] {$x_{k+1}=\overline{A} x_k + \overline{B} u_k$};

		\draw[->]
		($(sys.east)+(0,0.2cm)$) -- ++(\arrowlenshort,0)
		node[midway, above] {$\mathcal{J}_{k}$};

		\draw[->]
		(dp.south)
		-- ++(0,-0.5)        % vertical segment
		-- ++(1.7cm,0)                     % horizontal segment to the right
		node[pos=0.3, align=center, yshift=-5.5mm] {Optimal control $u_k$ \\ with minimal cost $\mathcal{J}$};

		\draw[->]
		(2.8cm,-1.1cm)
		-- (2.8cm, -0.2cm)
		-- ($(sys.west)+(0,-0.2cm)$)
		node[midway, below] {$Q,\, R$};


	\end{tikzpicture}
    \begin{itemize}
				\setlength{\itemsep}{\bulletSpacing}
				\item Sampling Density and Sampling Method Cost\\[2mm]
				\item Sampling Methods for finding $\{t_0, \, \ldots, t_N \}$
				      \begin{enumerate}
					      \item Periodic sampling
					      \item Lebesgue sampling
					      \item Quantization-based sampling
				      \end{enumerate}
			\end{itemize}
\end{frame}


\begin{frame}{Comparing Sampling Methods: Sampling Density}
	% \begin{columns}
	% \begin{column}{0.7\textwidth}

	%\resizebox{1.\textwidth}{!}{
    \vspace{-0.3cm}

	\begin{block}{Sampling Density}
		Given $x_0$, $A$, $B$, $Q$, $R$, and $S$, and interval length $T$, and a number of samples $N$, the \emph{sampling density} $\sigma_{N,m}:[0,T] \to \mathbb{R}^{+}$ of any sampling method $m$ is defined as
		\[
			\sigma_{N,m}(t) = \frac{1}{N\,\tau_{k}} \quad \forall t \in [t_k, t_{k+1}), \quad k \in \{0, \ldots, N-1\}
		\]
		\vspace{-1em}

		\begin{itemize}
			\item Temporal distrubtion of sampling instants
			\item Sampling density is normalized
		\end{itemize}
	\end{block}
	% }
	% \resizebox{1\textwidth}{!}
	%{
    \vspace{-0.3cm}
	\only<2>{\begin{example}[$T=5$, $N=4$]
			
        \begin{tabular}{@{}p{0.5\linewidth}@{} p{0.5\linewidth}@{}}
            \vspace{-0.3cm}
            \begin{itemize}
                \item $\sigma_4\,(t) = \frac{1}{4\,\cdot\,1} = \frac{1}{4}, \quad \forall t \in [0,1)$\\[0.3cm]
                \item $\sigma_4\,(t) = \frac{1}{4\,\cdot\,3} = \frac{1}{12}, \quad \forall t \in [1,4)$
            \end{itemize}
            &
            \hspace{-0.1cm}
                            \vspace{-0.9cm}

            \includegraphics[width=\linewidth]{plots/density_plot.pdf}
        \end{tabular}

		\end{example}}
	\only<1>{\begin{block}{Asymptotic Sampling Density}
			To remove the dependency on $N$, we define the \emph{asymptotic sampling density} as $\sigma_{m}:[0,T] \to \mathbb{R}^{+}$ as the limit
			\[
				\sigma_{m}(t) = \lim_{N \to \infty} \sigma_{N,m}(t)
			\]
		\end{block}
	}
	%}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Normalized Cost %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Comparing Sampling Methods: Normalized Cost}
	% \begin{columns}
	% \begin{column}{0.7\textwidth}

	%\resizebox{1.\textwidth}{!}{

	\begin{block}{Normalized Cost}
		Given $x_0$, $A$, $B$, $Q$, $R$, and $S$, and interval length $T$, and a number of samples $N$, the \emph{normalized cost} of any sampling method $m$ is defined as
		\[
			c_{N,m} =\frac{N^2}{T^2} \frac{\mathcal{J}_{N,m} - \mathcal{J}_\infty}{\mathcal{J}_\infty}
		\]
		where $\mathcal{J}_{N,m}$ is the minimal cost of the sampling method $m$ with $N$ samples, and $\mathcal{J}_\infty$ is the minimal cost of the continuous-time system.
	\end{block}
	% }
	% \resizebox{1\textwidth}{!}
	%{
	\begin{block}{Asymptotic Normalized Cost}
		To remove the dependency on $N$, we define the \emph{asymptotic normalized cost} as the limit
		\[
			c_{m} = \lim_{N \to \infty} c_{N,m}
		\]
	\end{block}
	%}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Comparing Sampling Methods: Normalized Cost}	
\vspace{-0.4cm}

\begin{example}[Normalized Cost for Periodic Sampling]
\begin{minipage}[t][6.5cm][t]{\linewidth}
\only<1>{
\hspace*{-0.04\linewidth}
\begin{tabular}{>{\centering\arraybackslash}p{0.5\linewidth} >{\centering\arraybackslash}p{0.5\linewidth}}
    $N=10$ & $N=60$ \\
    \includegraphics[width=\linewidth]{./plots/pointwise_N=10.pdf} &
    \includegraphics[width=\linewidth]{./plots/pointwise_N=60.pdf} \\[0.5mm]
    
    % Itemize nebeneinander
    \begin{itemize}
        \item $\mathcal{J}_{\infty}=383.2$,\, $\mathcal{J}_{10,\text{per}}=699.7$\\[0.2cm]
        \item $c_{10,\text{per}}=\frac{10^2}{6^2} \frac{699.7 - 383.2}{383.2}=2.3$ 
    \end{itemize} &
    \begin{itemize}
        \item $\mathcal{J}_{\infty}=383.2$, \, $\mathcal{J}_{60,\text{per}}=385.5$\\[0.2cm]
        \item $c_{60,\text{per}}= \frac{60^2}{6^2} \frac{385.5 - 383.2}{383.2}=0.6$
    \end{itemize}
    
\end{tabular}
}
    \only<2>{
    \centering
    \includegraphics[height=6.5cm]{./plots/normalized_cost_vs_N.pdf} 

}
\end{minipage}

\end{example}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Periodic Sampling %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Periodic Sampling}
	We divide the interval $[0,T]$ into $N$ parts of equal size
	\[
		\begin{array}{>{\displaystyle}ll}
			\tau_k = \tau = \frac{T}{N}, & k \in \{0, \ldots, N-1\} \\[8pt]
			t_k = k \cdot \frac{T}{N},   & k \in \{0, \ldots, N\}
		\end{array}
	\]

	For $N \in \mathbb{N}$, we get the constant sampling density
	\[
		\sigma_{per, N}(t) = \frac{1}{N\cdot t_k}
		= \frac{1}{N}\cdot \frac{N}{T}
		= \frac{1}{T}
	\]
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Periodic Sampling: Optimal Control}
	For sampling period $\tau$, the solution $\overline{K}\,(\tau)$ of the discrete-time Riccati equation can be determined analytically as

	\[
		\overline{K}\,(\tau) = K_{\infty} + X \cdot \frac{\tau^2}{2} + o(\tau^2) \quad [1]
	\] 

	where $K_{\infty}$ is the solution of the continuous-time Riccati equation, and $X$ is the solution of a Lyapunov equation\footnote{}


	\bigskip

	\begin{columns}
		\begin{column}{0.7\textwidth}

			{
				\color{gray!80}
				\textit{
					$\ldots$ informally, optimal controller of the discrete-time can be expressed as the continuous-time solution $K_\infty$ plus a correction term that is proportional to the square of the sampling period $\tau$.
				}
			}
		\end{column}
	\end{columns}

    \vspace{0.9cm}
	\begin{footnotesize}
		$^1$ Melzer, Stuart M., and Benjamin C. Kuo. "Sampling period sensitivity of the optimal sampled \\[0.1mm]
        data linear regulator." Automatica 7.3 (1971): 367-370.
	\end{footnotesize}

\end{frame}

% Question slide
\questionslide{
	Should there be a [1] in the equation, or only after Lyapunov equation?
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Periodic Sampling: Asymptotic Normalized Cost}
	\begin{columns}
		\begin{column}{0.5\textwidth}
			\begin{equationbox}[1\textwidth]
				c_{N,\text{per}} =\frac{N^2}{T^2} \frac{\mathcal{J}_{N,\text{per}} - \mathcal{J}_\infty}{\mathcal{J}_\infty}
			\end{equationbox}
		\end{column}


		\begin{column}{0.5\textwidth}
			\begin{equationbox}[1\textwidth]
				\overline{K}\,(\tau) = K_{\infty} + X \cdot \frac{\tau^2}{2} + o(\tau^2)
			\end{equationbox}
		\end{column}
	\end{columns}


	% \resizebox{1.1\textwidth}{!}{$
	% \[
	% 	\begin{array}{>{\displaystyle}rcl}
	% 		c_{\text{per}} & = & \lim\limits_{N \to \infty} \frac{N^2}{T^2} \, \frac{x_{0}' \, \overline{K}(\tau)\, x_0 - x_{0}' \, {K}_{\infty}\, x_0}{x_{0}' \, K_\infty \,x_0}                                                                       \\
	% 		               & = & \lim\limits_{N \to \infty} \frac{N^2}{T^2} \, \frac{x_{0}' \,   \left( K_\infty + X\cdot \frac{\tau^2}{2} + o(\tau^2) \right)    \, x_0 - x_{0}' \, {K}_{\infty}\, x_0}{x_{0}' \, K_\infty \,x_0}                      \\
	% 		               & = & \lim\limits_{N \to \infty} \frac{N^2}{T^2} \, \frac{x_{0}' \,   \left( K_\infty + X\cdot \frac{T^2}{2N^2} + o\left(\frac{T^2}{2N^2}\right) \right)    \, x_0 - x_{0}' \, {K}_{\infty}\, x_0}{x_{0}' \, K_\infty \,x_0} \\
	% 		               & = & \lim\limits_{N \to \infty} \frac{N^2}{T^2} \, \frac{
	% 			x_0' \,\frac{XT^2}{2N^2} \, x_0 + x_0' \,o\left(N^{-2}\right)\,x_0
	% 		}{x_{0}' \, K_\infty \,x_0}                                                                                                                                                                                                                 \\
	% 		               & = & \frac{x_0' \, X \, x_0}{2\, x_0'\, K_{\infty} \, x_0}
	% 	\end{array}
	% \]

	\newcommand{\LineSpacing}{0.4mm}
	{\footnotesize	\begin{eqnarray*}
			c_{\text{per}} & = & \lim\limits_{N \to \infty} \frac{N^2}{T^2} \, \frac{x_{0}' \, \overline{K}(\tau)\, x_0 - x_{0}' \, {K}_{\infty}\, x_0}{x_{0}' \, K_\infty \,x_0} \\[\LineSpacing]
			& = & \lim\limits_{N \to \infty} \frac{N^2}{T^2} \, \frac{x_{0}' \, \left( K_\infty + X\cdot \frac{\tau^2}{2} + o(\tau^2) \right) \, x_0 - x_{0}' \, {K}_{\infty}\, x_0}{x_{0}' \, K_\infty \,x_0} \\[\LineSpacing]
			& = & \lim\limits_{N \to \infty} \frac{N^2}{T^2} \, \frac{x_{0}' \, \left( K_\infty + X\cdot \frac{T^2}{2N^2} + o\left(\frac{T^2}{2N^2}\right) \right) \, x_0 - x_{0}' \, {K}_{\infty}\, x_0}{x_{0}' \, K_\infty \,x_0} \\[\LineSpacing]
			& = & \lim\limits_{N \to \infty} \frac{N^2}{T^2} \, \frac{x_0' \,\frac{XT^2}{2N^2} \, x_0 + x_0' \,o\left(N^{-2}\right)\,x_0}{x_{0}' \, K_\infty \,x_0} \\[0mm]
			& = & \frac{x_0' \, X \, x_0}{2\, x_0'\, K_{\infty} \, x_0}
		\end{eqnarray*}
	}

\end{frame}


% Question slide
% \begin{frame}{NOTES}
% 	\begin{questionbox}
% 		The boxes are not boxing :(
% 	\end{questionbox}
% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Periodic Sampling: Example}
	\centering
    \vspace{-0.5cm}
	\begin{equationbox}[4cm]
		c_{\text{per}} = \frac{x_0' \, X \, x_0}{2\, x_0'\, K_{\infty} \, x_0}
	\end{equationbox}

	\begin{example}
		For a first-order system $(n=1)$, wlog\ $B = R = 1$, we obtain
		\[
			\begin{aligned}
				X        & = \frac{1}{12} (K_\infty - A) K_\infty^2, \\
				K_\infty & = A + \sqrt{A^2 + Q}.
			\end{aligned}
		\]

		which gives us the asymptotic normalized cost
		\[
			c_{\text{per}} = \frac{1}{24} A \sqrt{A^2 + Q} + A^2 + Q .
		\]
	\end{example}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Lebesgue Sampling %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Deterministic Lebesgue Sampling}

	\begin{itemize}
		\item \textbf{Intuition:} Sample more frequently where the control changes faster
		\item Sample whenever the optimal $u$ changes by a fixed threshold $\Delta$, so after any sampling instant $t_k$, the next $t_{k+1}$ is determined s.t.
		      $$
			      \left\| \,u\,(t_{t+1}) - u(t_k)\, \right\|=\,\Delta
		      $$

		      where $u$ is the optimal continuous-time input
	\end{itemize}

	\begin{example}[$\Delta=7$]			
        \centering
        \includegraphics[height=3cm]{plots/lebesgue_plot.pdf} 
	\end{example}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Deterministic Lebesgue Sampling}
    \centering
    \vspace{-0.3cm}
	\begin{equationbox}[6cm]
		\left\| \,u\,(t_{t+1}) - u(t_k)\, \right\|=\,\Delta
	\end{equationbox}
    \vspace{-0.2cm}
	\begin{example}[$\Delta=7$]			
        \centering
        \includegraphics[height=5.4cm]{plots/lebesgue_plot.pdf} 
	\end{example}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Deterministic Lebesgue Sampling}

	\centering

	\begin{equationbox}[6cm]
		\left\| \,u\,(t_{t+1}) - u(t_k)\, \right\|=\,\Delta
	\end{equationbox}
        \bigskip

   {\raggedright
In the case of a scalar input ($m=1$) and a given number $N$ of sampling instances in $[0,T]$, the sampling instants $t_k$ satisfy
\par}
	\newcommand{\LineSpacing}{0mm}

	\begin{eqnarray*}
		\int_{t_k}^{t_{k+1}} |\,\dot{u}\,(t)\,|\,dt & = & |\,u\,(t_{k+1}) - u\,(t_{k})\,| \, = \, \Delta \\[\LineSpacing]
		& = & \frac{1}{N} \cdot \underbrace{\int_{0}^T \, |\, \dot{u}\,(t) \,| \, dt}_{N\cdot\Delta}
	\end{eqnarray*}

\end{frame}

\begin{frame}{Deterministic Lebesgue Sampling: Sampling Density}

	\centering
	\begin{equationbox}[8cm]
		\int_{t_k}^{t_{k+1}} |\,\dot{u}\,(t)\,|\,dt =
		\frac{1}{N} \cdot {\int_{0}^T \, |\, \dot{u}\,(t) \,| \, dt}
	\end{equationbox}
    \vspace{-0.6cm}
	{\Large\[
		\begin{array}{>{\displaystyle}rcl}
			\sigma_{\text{dls}}\, (t) & = & \frac{1}{N\cdot\tau_k}\\[5mm]                                              
            & = & \frac{\int_{t_k}^{t_{k+1}} |\,\dot{u}\,(t)\,|\,dt}{\int_{0}^T \, |\, \dot{u}\,(t) \,| \, dt} \cdot \frac{1}{\tau_k} \\[5mm]
            & = & \frac{\int_{t_k}^{t_{k+1}} |\,\dot{u}\,(t)\,|\,dt}{\tau_k} \cdot \frac{1}{\int_{0}^T \, |\, \dot{u}\,(t) \,| \, dt} \\[5mm]
            & = & \frac{|\,u\,(t_{k+1}) - u\,(t_{k})\,|}{t_{k+1} - t_k} \cdot \frac{1}{\int_{0}^T \, |\, \dot{u}\,(t) \,| \, dt}
		\end{array}
	\]}

	% 	\newcommand{\LineSpacing}{-0mm}
	% {\tiny\begin{eqnarray*}
	%     \sigma_{\text{dls}}\, (t) & = & \frac{1}{N\cdot\tau_k} \\[\LineSpacing]
	%                               & = & \frac{\displaystyle\int_{t_k}^{t_{k+1}} |\,\dot{u}\,(t)\,|\,dt}{\int_{0}^T \, |\, \dot{u}\,(t) \,| \, dt} \cdot \frac{1}{\tau_k} \\[\LineSpacing]
	%                               & = & \frac{\displaystyle\int_{t_k}^{t_{k+1}} |\,\dot{u}\,(t)\,|\,dt}{\tau_k} \cdot \frac{1}{\displaystyle\int_{0}^T \, |\, \dot{u}\,(t) \,| \, dt} \\[\LineSpacing]
	%                               & = & \frac{|\,u\,(t_{k+1}) - u\,(t_{k})\,|}{t_{k+1} - t_k} \cdot \frac{1}{\int_{0}^T \, |\, \dot{u}\,(t) \,| \, dt}
	% \end{eqnarray*}
	% }

	% \begin{itemize}
	% 	\item Sampling intervals vary depending on $|\,\dot{u \, (t)}\,|$
	% 	\item No closed formula for the asymptotic normalized cost $c_{\text{dls}}$
	% \end{itemize}

\end{frame}


\questionslide{
	Last equation missing
}
